# ARQUITETURA DE SOFTWARE - 25.2

## Stream Processing com Apache Flink (SPAF)

![Apache Flink E-Commerce Analytics with Elasticsearch and Postgres](architecture_img.png)

### 1. O que vai ser feito?
Vamos construir um pipeline que processa dados de vendas simuladas em tempo real para gerar m√©tricas e an√°lises imediatas. Os eventos transitam por Kafka, s√£o processados pelo Apache Flink, e os resultados ficam dispon√≠veis para consulta e visualiza√ß√£o.

### 2. Como vai ser feito?
- **Gera√ß√£o de dados**: Locust Script Python gera vendas fict√≠cias (50 a 100 eventos por segundo).
- **Ingest√£o e transporte**: Os eventos v√£o para um t√≥pico do Apache Kafka.
- **Processamento**: Apache Flink consome os dados, faz agrega√ß√µes (vendas por categoria, detec√ß√£o de anomalias).
- **Armazenamento**: Resultados salvos em PostgreSQL.

### 3. M√©tricas a serem avaliadas
- Lat√™ncia entre gera√ß√£o e visualiza√ß√£o dos dados (end-to-end delay).
- Throughput do sistema (eventos processados por segundo).
- Consumo de recursos (CPU e mem√≥ria) dos componentes principais (Kafka, Flink).
- Precis√£o e consist√™ncia das agrega√ß√µes e detec√ß√µes feitas pelo Flink.

### 4. An√°lise e apresenta√ß√£o dos resultados
- Apresentar gr√°ficos de lat√™ncia e throughput em diferentes cargas (ex: 10, 50, 100 eventos/s).
- Apresenta√ß√£o sobre as ferramentas utilizadas no projeto.
- Discorrer sobre a arquitetura, poss√≠veis falhas e melhorias futuras.

---

## üìå Arquitetura

![Arquitetura do Pipeline](arquitetura.png)

---

## ‚öôÔ∏è Pr√©-requisitos

- **Docker** e **Docker Compose**  
- **Python 3.10+** com `venv` configurado  
- **Maven 3+** e **Java 11+**  

---

## üê≥ Subindo os servi√ßos

Na raiz do projeto:

```bash
docker-compose up -d
```

Verifique se os containers est√£o rodando:

```bash
docker ps --format "table {{.Names}}	{{.Status}}"
```

Voc√™ deve ver algo como:
```
zookeeper   Up
kafka       Up
postgres    Up (healthy)
jobmanager  Up
taskmanager Up
kafka-ui    Up
```

---

## üì¶ Criando o t√≥pico no Kafka

```bash
docker exec -it kafka kafka-topics   --create   --topic vendas-simuladas   --bootstrap-server localhost:9092   --partitions 1 --replication-factor 1
```

Listar os t√≥picos:

```bash
docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9092
```

---

## üìù Gerando eventos com Locust

1. Ative o ambiente virtual:
   ```bash
   source venv/bin/activate
   ```

2. Instale o Locust (se ainda n√£o fez):
   ```bash
   pip install locust
   ```

3. Rode o script:
   ```bash
   locust -f locust/sales_generator.py
   ```

4. Acesse a UI do Locust:  
   üëâ [http://localhost:8089](http://localhost:8089)

   Configure:
   - Usu√°rios: `100`  
   - Taxa de spawn: `50`  
   - Host: `http://localhost:9092`  

---

## ‚ö° Rodando o Job no Flink

Compile e gere o **JAR empacotado**:

```bash
mvn clean package -DskipTests
```

Copie o JAR para o JobManager:

```bash
docker cp target/spaf-1.0-SNAPSHOT-shaded.jar jobmanager:/opt/flink/
```

Execute o job:

```bash
docker exec -it jobmanager flink run   -c com.example.spaf.SalesJob   /opt/flink/spaf-1.0-SNAPSHOT-shaded.jar
```

---

## üóÑÔ∏è Consultando no PostgreSQL

Acesse o banco:

```bash
docker exec -it postgres psql -U postgres -d postgres
```

Veja os dados processados:

```sql
SELECT * FROM sales_summary ORDER BY created_at DESC LIMIT 10;
```

---

## üìä Dashboards

- **Kafka UI** ‚Üí [http://localhost:8080](http://localhost:8080)  
- **Locust** ‚Üí [http://localhost:8089](http://localhost:8089)  
- **Flink Dashboard** ‚Üí [http://localhost:8081](http://localhost:8081)  

---
